{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         año  mes  dia  hora  minuto  activa  reactiva  aparente     l1  \\\n",
      "0       2021    1    1     0       0  13.584     9.264    16.444  29.16   \n",
      "1       2021    1    1     0      15  12.492     9.840    15.904  27.30   \n",
      "2       2021    1    1     0      30  12.468    10.056    16.016  27.12   \n",
      "3       2021    1    1     0      45  13.032     9.060    15.872  27.18   \n",
      "4       2021    1    1     1       0  12.540     9.720    15.868  27.12   \n",
      "...      ...  ...  ...   ...     ...     ...       ...       ...    ...   \n",
      "117200  2024    5    6     8      45  45.840     3.564    45.980  74.16   \n",
      "117201  2024    5    6     9       0  52.092     3.084    52.184  77.97   \n",
      "117202  2024    5    6     9      15  51.996     2.448    52.052  74.55   \n",
      "117203  2024    5    6     9      30  53.472     2.316    53.524  77.43   \n",
      "117204  2024    5    6     9      45  59.472     2.280    59.516  82.71   \n",
      "\n",
      "            l2     l3  \n",
      "0        25.62  20.85  \n",
      "1        24.81  20.34  \n",
      "2        25.56  20.64  \n",
      "3        25.02  20.70  \n",
      "4        25.17  20.10  \n",
      "...        ...    ...  \n",
      "117200   76.29  62.10  \n",
      "117201   77.64  80.79  \n",
      "117202   85.26  73.89  \n",
      "117203   90.87  71.88  \n",
      "117204  111.63  72.39  \n",
      "\n",
      "[117205 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "corrientes = pd.read_csv('corrientes.csv')\n",
    "potencias = pd.read_csv('potencias.csv')\n",
    "\n",
    "corrientes['timestamp'] = pd.to_datetime(corrientes['timestamp'])\n",
    "potencias['timestamp'] = pd.to_datetime(potencias['timestamp'])\n",
    "\n",
    "# Unir los dataframes en base al ID y timestamp\n",
    "merged_df = pd.merge(corrientes, potencias, on=['id', 'timestamp'])\n",
    "\n",
    "# Separar la columna de timestamp en año, mes, día, hora, minuto\n",
    "merged_df['año'] = merged_df['timestamp'].dt.year\n",
    "merged_df['mes'] = merged_df['timestamp'].dt.month\n",
    "merged_df['dia'] = merged_df['timestamp'].dt.day\n",
    "merged_df['hora'] = merged_df['timestamp'].dt.hour\n",
    "merged_df['minuto'] = merged_df['timestamp'].dt.minute\n",
    "\n",
    "# Seleccionar y reorganizar las columnas en el formato deseado\n",
    "final_df = merged_df[['año', 'mes', 'dia', 'hora', 'minuto', 'activa', 'reactiva', 'aparente', 'l1', 'l2', 'l3']]\n",
    "\n",
    "# Mostrar el dataframe resultante\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Armamos los datos con el formato que queremos\n",
    "X = np.concatenate([activapre, aparentepre, reactivapre, mespre, diapre, minutopre, i1pre, i2pre, i3pre], axis=1)\n",
    "y = activapost  # Supongamos que queremos predecir la 'activa' post ventana\n",
    "\n",
    "archivo_salida = 'datos.txt'\n",
    "\n",
    "nombre_columna = 'X'\n",
    "\n",
    "# Abre el archivo de texto para escritura\n",
    "with open(archivo_salida, 'w') as f:\n",
    "    # Itera sobre las filas del array X\n",
    "    for fila in X:\n",
    "        # Convierte cada fila a una cadena de texto con valores separados por comas\n",
    "        fila_str = ','.join(map(str, fila))\n",
    "        # Escribe la fila en el archivo y añade una nueva línea\n",
    "        f.write(f\"{fila_str}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scalerX = StandardScaler()\n",
    "scalery = StandardScaler()\n",
    "\n",
    "# Assuming y is a 1D array, reshape it to 2D\n",
    "y_reshaped = y.reshape(-1, 1)\n",
    "\n",
    "# Fit and transform X and y_scaled\n",
    "X_train = scalerX.fit_transform(X_train)\n",
    "X_val = scalerX.fit_transform(X_val)\n",
    "X_test = scalerX.fit_transform(X_test)\n",
    "\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "y_train = scalery.fit_transform(y_train)\n",
    "y_val = scalery.fit_transform(y_val)\n",
    "y_test = scalery.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio = np.nanmean(y_train)\n",
    "# Reemplazar NaN por el promedio calculado\n",
    "y_train[np.isnan(y_train)] = promedio\n",
    "\n",
    "promedio = np.nanmean(X_train)\n",
    "# Reemplazar NaN por el promedio calculado\n",
    "X_train[np.isnan(X_train)] = promedio\n",
    "\n",
    "promedio = np.nanmean(X_val)\n",
    "# Reemplazar NaN por el promedio calculado\n",
    "X_val[np.isnan(X_val)] = promedio\n",
    "\n",
    "promedio = np.nanmean(y_val)\n",
    "# Reemplazar NaN por el promedio calculado\n",
    "y_val[np.isnan(y_val)] = promedio\n",
    "\n",
    "promedio = np.nanmean(X_test)\n",
    "# Reemplazar NaN por el promedio calculado\n",
    "X_test[np.isnan(X_test)] = promedio\n",
    "\n",
    "promedio = np.nanmean(y_test)\n",
    "# Reemplazar NaN por el promedio calculado\n",
    "y_test[np.isnan(y_test)] = promedio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copia_datos = X\n",
    "copia_datos\n",
    "copia_datos2 = copia_datos\n",
    "print(copia_datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_escalados = scalerX.fit_transform(copia_datos2)\n",
    "print(datos_escalados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_desescalados = scalerX.inverse_transform(datos_escalados)\n",
    "print(datos_desescalados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones con los datos de prueba\n",
    "y_test_pred = model.predict(X_test[25,:].reshape(1, -1))\n",
    "y_test[25]\n",
    "print(y_test_pred)\n",
    "# X ENTRA año  mes  dia  hora  minuto  activa  reactiva  aparente l1 L2 L2\n",
    "input_data = np.array([0.11835867,  0.09746048,  0.02965695,  0.10309789,  0.18152911 , 0.16393361,\n",
    "                       0.11301236,  0.1646457,   1.12972061,  1.14726251 , 1.23655089,  1.11053278,\n",
    "                       0.53465572,  0.53495438 , 0.53488847 , 0.53481257 ,-1.10291196 ,-1.10285512,\n",
    "                      -1.10314401 ,-1.10344726,  0.44668967 , 1.33936005 ,-1.34082598 ,-0.44214717,\n",
    "                      -0.42645304 ,-0.43415975, -0.51742309 ,-0.44604964 , 0.78809792, 0.76781543,\n",
    "                       0.72352641 , 0.78930282, -0.00159766, -0.04054386, -0.06245636 ,-0.02779989])\n",
    "\n",
    "# Ajusta la forma para que coincida con las características utilizadas durante el entrenamiento\n",
    "input_data = input_data.reshape(1, -1) #si se ocmenta no anda\n",
    "\n",
    "# Realiza la predicción\n",
    "y_test_pred = model.predict(input_data)\n",
    "\n",
    "print(y_test_pred)\n",
    "y_test_pred = scalery.inverse_transform(y_test_pred)\n",
    "print(y_test_pred)\n",
    "\n",
    "#a = scalery.inverse_transform([-0.07620964])\n",
    "#print(a)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_train, label='Actual')\n",
    "plt.plot(y_test_pred, label='Predicción')\n",
    "plt.xlabel('Índice de muestra')\n",
    "plt.ylabel('Potencia Activa')\n",
    "plt.title('Predicción vs Actual (Datos de Entrenamiento)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = scalery.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test[156,:].reshape(1, -1))\n",
    "print(y_test_pred)\n",
    "\n",
    "y_test_pred = scalery.inverse_transform(y_test_pred)\n",
    "print(y_test_pred)\n",
    "\n",
    "#a = scalery.inverse_transform([-0.07620964])\n",
    "print(\"en test esa pos tenia\")\n",
    "print(y_test[156])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_train, label='Actual')\n",
    "plt.plot(y_test_pred, label='Predicción')\n",
    "plt.xlabel('Índice de muestra')\n",
    "plt.ylabel('Potencia Activa')\n",
    "plt.title('Predicción vs Actual (Datos de Entrenamiento)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Supongamos que model es tu modelo ya entrenado y X_test, y_test son tus datos de prueba\n",
    "# Hacemos predicciones\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "has_nan = np.isnan(y_test_pred).any()\n",
    "print(\"¿Hay NaN en los datos y_test_pred?\", has_nan)\n",
    "nan_positions = np.argwhere(np.isnan(y_test_pred))\n",
    "print(\"Posiciones de NaN en los datos X:\")\n",
    "print(nan_positions)\n",
    "\n",
    "y_test_pred[np.isnan(y_test_pred)] = promedio\n",
    "\n",
    "y_test_pred = scalery.inverse_transform(y_test_pred)\n",
    "\n",
    "\n",
    "\n",
    "has_nan = np.isnan(y_test).any()\n",
    "print(\"¿Hay NaN en los datos y_Test?\", has_nan)\n",
    "nan_positions = np.argwhere(np.isnan(y_test))\n",
    "print(\"Posiciones de NaN en los datos X:\")\n",
    "print(nan_positions)\n",
    "\n",
    "y_test[np.isnan(y_test)] = promedio\n",
    "\n",
    "\n",
    "# Calculamos el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Calculamos otras métricas de error\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Imprimimos las métricas de error\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R²: {r2}')\n",
    "\n",
    "# Definimos un margen de error aceptable (por ejemplo, 10 unidades) 12.45\n",
    "margin_of_error = 10\n",
    "\n",
    "# Calculamos cuántas predicciones están dentro del margen de error\n",
    "within_margin = np.sum(np.abs(y_test - y_test_pred) <= margin_of_error)\n",
    "total_predictions = len(y_test)\n",
    "accuracy_within_margin = within_margin / total_predictions\n",
    "\n",
    "# Imprimimos la precisión dentro del margen de error\n",
    "print(f'Número de predicciones dentro del margen de error: {within_margin}')\n",
    "print(f'Precisión dentro del margen de error: {accuracy_within_margin:.2%}')\n",
    "\n",
    "# Guardamos los resultados en un DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_test_pred,\n",
    "    'Error': y_test - y_test_pred\n",
    "})\n",
    "\n",
    "# Guardamos los resultados en un archivo CSV\n",
    "results_df.to_csv('predictions_and_errors.csv', index=False)\n",
    "\n",
    "# Guardamos las métricas de error en un archivo JSON\n",
    "import json\n",
    "\n",
    "metrics = {\n",
    "    'MSE': mse,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R²': r2,\n",
    "    'Precision within margin': accuracy_within_margin\n",
    "}\n",
    "\n",
    "with open('model_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_salida = \"datos_estimados.txt\"\n",
    "# Abre el archivo de texto para escritura\n",
    "with open(archivo_salida, 'w') as f:\n",
    "    # Itera sobre los valores de y_train\n",
    "    for x_test in y_test_pred:\n",
    "        # Escribe el valor de y_train en el archivo y añade una nueva línea\n",
    "        f.write(f\"{x_test}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_salida = \"datos_en_y_test.txt\"\n",
    "# Abre el archivo de texto para escritura\n",
    "with open(archivo_salida, 'w') as f:\n",
    "    # Itera sobre los valores de y_train\n",
    "    for x_test in y_test:\n",
    "        # Escribe el valor de y_train en el archivo y añade una nueva línea\n",
    "        f.write(f\"{x_test}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot de datos de entrenamiento\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_train, label='Actual (Train)', marker='o')\n",
    "plt.plot(y_test_pred, label='Predicted (Train)', marker='x')\n",
    "plt.title('Comparación de Predicciones y Valores Reales (Datos de Entrenamiento)')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Potencia Activa')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot de datos de prueba\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Ploteamos los datos reales y predichos como líneas\n",
    "plt.plot(y_test, label='Reales (Test)', linestyle='-', color='blue')\n",
    "plt.plot(y_test_pred, label='Predichas (Test)', linestyle='-', color='red')\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Comparación de Predicciones y Valores Reales (Datos de Prueba)')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Potencia Activa')\n",
    "\n",
    "# Añadimos la leyenda y la cuadrícula\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Calculamos el error (diferencia entre los valores reales y predichos)\n",
    "error = y_test[:50] - y_test_pred[:50]\n",
    "\n",
    "# Plot de datos de prueba\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Ploteamos los primeros 50 datos reales y predichos como líneas\n",
    "plt.plot(y_test[:50], label='Reales (Test)', linestyle='-', color='blue')\n",
    "plt.plot(y_test_pred[:50], label='Predichas (Test)', linestyle='-', color='red')\n",
    "\n",
    "# Ploteamos el error como línea\n",
    "plt.plot(error, label='Error (Reales - Predichas)', linestyle='-', color='green')\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Comparación de Predicciones y Valores Reales (Datos de Prueba)')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Potencia Activa')\n",
    "\n",
    "# Añadimos la leyenda y la cuadrícula\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot de datos de prueba\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "error = y_test[50:100] - y_test_pred[50:100]\n",
    "\n",
    "# Ploteamos los primeros 100 datos reales y predichos como líneas\n",
    "plt.plot(y_test[50:100], label='Reales (Test)', linestyle='-', color='blue')\n",
    "plt.plot(y_test_pred[50:100], label='Predichas (Test)', linestyle='-', color='red')\n",
    "plt.plot(error, label='Error (Reales - Predichas)', linestyle='-', color='green')\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Comparación de Predicciones y Valores Reales (Datos de Prueba)')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Potencia Activa')\n",
    "\n",
    "# Añadimos la leyenda y la cuadrícula\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot de datos de prueba\n",
    "plt.figure(figsize=(12, 6))\n",
    "error = y_test[300:400] - y_test_pred[300:400]\n",
    "\n",
    "# Ploteamos los primeros 100 datos reales y predichos como líneas\n",
    "plt.plot(y_test[300:400], label='Reales (Test)', linestyle='-', color='blue')\n",
    "plt.plot(y_test_pred[300:400], label='Predichas (Test)', linestyle='-', color='red')\n",
    "plt.plot(error, label='Error (Reales - Predichas)', linestyle='-', color='green')\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Comparación de Predicciones y Valores Reales (Datos de Prueba)')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Potencia Activa')\n",
    "\n",
    "# Añadimos la leyenda y la cuadrícula\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot de datos de prueba\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Ploteamos los primeros 100 datos reales y predichos como líneas\n",
    "plt.plot(y_test[850:1000], label='Reales (Test)', linestyle='-', color='blue')\n",
    "plt.plot(y_test_pred[850:1000], label='Predichas (Test)', linestyle='-', color='red')\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Comparación de Predicciones y Valores Reales (Datos de Prueba)')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Potencia Activa')\n",
    "\n",
    "# Añadimos la leyenda y la cuadrícula\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()\n",
    "\n",
    "\n",
    "error = y_test - y_test_pred\n",
    "print((error))\n",
    "\n",
    "\n",
    "# Creamos un histograma del error\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(-15, 15)\n",
    "\n",
    "plt.hist(error, bins=500, edgecolor='black', color='blue')\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Histograma del Error (Reales - Predichas)')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation = np.std(error)\n",
    "\n",
    "print(f\"Desviación estándar del error: {std_deviation:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
